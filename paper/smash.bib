@article{Su2013Adaptive,
    abstract = {{Boundary effects are caused by incomplete data in the boundary regions when the analysis window gets closer to the edge of a signal. Various extension schemes have been developed to handle the boundaries of finite length signals to reduce the boundary effects. Zero padding, periodic extension, and symmetric extension are some basic extension methods. However, these solutions have drawbacks. In this paper, we consider the problem of handling the boundary effects due to improper extension methods in the wavelet transform for the application of fault diagnosis of rotating machine. An extension algorithm based on curve fitting with properties that make it more suitable for boundary effects reduction is presented. This extension algorithm could preserve the time-varying characteristics of the signals and be effective to reduce distortions appearing at the boundary. Then, an interpolation approach is used in the boundary effects region to further alleviate the distortions. Procedures for realization of these two algorithms and relative issues are presented. Several experimental tests show that the proposed algorithms are efficient to alleviate the boundary effects in comparison to the existing extension methods.}},
    author = {Su, Hang and Liu, Quan and Li, Jingsong},
    citeulike-article-id = {13840345},
    citeulike-linkout-0 = {http://dx.doi.org/10.1155/2013/540172},
    citeulike-linkout-1 = {http://ade.sagepub.com/content/5/540172.abstract},
    citeulike-linkout-2 = {http://ade.sagepub.com/content/5/540172.full.pdf},
    day = {01},
    doi = {10.1155/2013/540172},
    issn = {1687-8140},
    journal = {Advances in Mechanical Engineering},
    keywords = {boundary, shrinkage, wavelet},
    month = jan,
    pages = {540172+},
    posted-at = {2015-11-17 19:13:34},
    priority = {2},
    publisher = {SAGE Publications},
    title = {{Adaptive Approach for Boundary Effects Reduction in Rotating Machine Signals Analysis}},
    url = {http://dx.doi.org/10.1155/2013/540172},
    volume = {5},
    year = {2013}
}

@article{Timmermann1999Multiscale,
    author = {Timmermann, Klaus E. and Nowak, Robert D.},
    citeulike-article-id = {13839869},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/18.761328},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=761328},
    doi = {10.1109/18.761328},
    institution = {Dept. of Electr. Eng., Michigan State Univ., East Lansing, MI, USA},
    issn = {0018-9448},
    journal = {Information Theory, IEEE Transactions on},
    keywords = {bayesian, multiscale, poisson},
    month = apr,
    number = {3},
    pages = {846--862},
    posted-at = {2015-11-17 05:45:07},
    priority = {2},
    publisher = {IEEE},
    title = {{Multiscale modeling and estimation of Poisson processes with application to photon-limited imaging}},
    url = {http://dx.doi.org/10.1109/18.761328},
    volume = {45},
    year = {1999}
}

@article{Kolaczyk1999Bayesian,
    abstract = {{Abstract I introduce a class of Bayesian multiscale models (BMSM's) for one-dimensional inhomogeneous Poisson processes. The focus is on estimating the (discretized) intensity function underlying the process. Unlike the usual transform-based approach at the heart of most wavelet-based methods for Gaussian data, these BMSM's are constructed using recursive dyadic partitions (RDP's) within an entirely likelihood-based framework. Each RDP may be associated with a binary tree, and a new multiscale prior distribution is introduced for the unknown intensity through the placement of mixture distributions at each of the nodes of the tree. The concept of model mixing is then applied to a complete collection of such trees. In addition to allowing for the inclusion of full location/scale information in the model, this last step also is fundamental both in inducing stationarity in the prior distribution and in enabling a given intensity function to be approximated at the resolution of the data. Under squared-error loss, a closed-form recursive expression for the Bayes optimal estimator is derived, which makes computationally efficient implementation possible. The mixing parameters in the prior distribution can be interpreted as the ?fraction of homogeneity? in the underlying intensity function at each scale, and I provide an empirical Bayes approach to eliciting their values, resulting in the ability to quantify multiscale structure in the data. The practical performance of the overall procedure is investigated through a series of simulations and illustrated using a real-data example from the field of high-energy astrophysics.}},
    author = {Kolaczyk, Eric D},
    citeulike-article-id = {13839867},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.1999.10474197},
    citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1999.10474197},
    day = {1},
    doi = {10.1080/01621459.1999.10474197},
    journal = {Journal of the American Statistical Association},
    keywords = {bayesian, multiscale, poisson},
    month = sep,
    number = {447},
    pages = {920--933},
    posted-at = {2015-11-17 05:41:50},
    priority = {2},
    publisher = {Taylor \& Francis},
    title = {{Bayesian Multiscale Models for Poisson Processes}},
    url = {http://dx.doi.org/10.1080/01621459.1999.10474197},
    volume = {94},
    year = {1999}
}

@article{Cai1999Incorporating,
    abstract = {{In standard wavelet methods, the empirical wavelet coefficients are thresholded term by term, on the basis of their individual magnitudes. Information on other coefficients has no influence on the treatment of particular coefficients. We propose a wavelet shrinkage method that incorporates information on neighboring coefficients into the decision making. The coefficients are considered in overlapping blocks; the treatment of coefficients in the middle of each block depends on the data in the whole block. The asymptotic and numerical performances of two particular versions of the estimator are investigated. We show that, asymptotically, one version of the estimator achieves the exact optimal rates of convergence over a range of Besov classes for global estimation, and attains adaptive minimax rate for estimating functions at a point. In numerical comparisons with various methods, both versions of the estimator perform excellently.}},
    author = {Cai, Tony T. and Silverman, Bernard W.},
    citeulike-article-id = {13839857},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.8745},
    keywords = {block, shrinkage, thresholding, wavelet},
    posted-at = {2015-11-17 05:27:06},
    priority = {2},
    title = {{Incorporating Information on Neighboring Coefficients into Wavelet Estimation}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.8745},
    year = {1999}
}

@inproceedings{Cai1998Adaptive,
    abstract = {{We study wavelet function estimation via the approach of block thresholding and ideal adaptation with oracle. Oracle inequalities are derived and serve as guides for the selection of smoothing parameters. Based on an oracle inequality and motivated by the data compression and localization properties of wavelets, an adaptive wavelet estimator for nonparametric regression is proposed and the optimality of the procedure is investigated. We show that the estimator achieves simultaneously three objectives: adaptivity, spatial adaptivity, and computational efficiency. Specifically, it is proved that the estimator attains the exact optimal rates of convergence over a range of Besov classes and the estimator achieves adaptive local minimax rate for estimating functions at a point. The estimator is easy to implement, at the computational cost of O(n). Simulation shows that the estimator has excellent numerical performance relative to more traditional wavelet estimators.  Keywords: Adaptivity; B...}},
    author = {Cai, Tony T.},
    booktitle = {Ann. Statist},
    citeulike-article-id = {13839856},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.9784},
    keywords = {block, shrinkage, thresholding, wavelet},
    pages = {898--924},
    posted-at = {2015-11-17 05:26:06},
    priority = {2},
    title = {{Adaptive Wavelet Estimation: A Block Thresholding And Oracle Inequality Approach}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.9784},
    year = {1998}
}

@article{Vidakovic2001BAMS,
    abstract = {{In this paper we address the problem of model-induced wavelet shrinkage. Assuming the independence model according to which the wavelet coecients are treated individually, we discuss a level-adaptive Bayesian model in the wavelet domain that has two important properties: (i) it realistically describes empirical properties of signals and images in the wavelet domain, and (ii) it results in simple optimal shrinkage rules to be used in fast wavelet denoising. The proposed denoising paradigm BAMS (short for Bayesian Adaptive Multiresolution Smoother) is illustrated on an array of Donoho and Johnstone's standard test functions and is compared to some standard wavelet-based smoothing methods.}},
    author = {Vidakovic, Brani and Ruggeri, Fabrizio},
    citeulike-article-id = {13839854},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.1836},
    keywords = {bayesian, shrinkage, wavelet},
    posted-at = {2015-11-17 05:23:10},
    priority = {2},
    title = {{BAMS Method: Theory And Simulations}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.1836},
    year = {2001}
}

@electronic{Coifman1995Translationinvariant,
    abstract = {{De-Noising with the traditional (orthogonal, maximally-decimated) wavelet transform sometimes exhibits visual artifacts; we attribute some of these – for example, Gibbs phenomena in the neighborhood of discontinuities – to the lack of translation invariance of the wavelet basis. One method to suppress such artifacts, termed  ” cycle spinning ” by Coifman, is to  ” average out ” the translation dependence. For a range of shifts, one shifts the data (right or left as the case may be), De-Noises the shifted data, and then unshifts the de-noised data. Doing this for each of a range of shifts, and averaging the several results so obtained, produces a reconstruction subject to far weaker Gibbs phenomena than thresholding based De-Noising using the traditional orthogonal wavelet transform. Cycle-Spinning over the range of all circulant shifts can be accomplished in order nlog 2(n) time; it is equivalent to de-noising using the undecimated or stationary wavelet transform. Cycle-spinning exhibits benefits outside of wavelet de-noising, for example in cosine packet denoising, where it helps suppress 'clicks'. It also has a counterpart in frequency domain de-noising, where the goal of translation-invariance is replaced by modulation invariance, and the central shift-De-Noise-unshift operation is replaced by modulate-De-Noise-demodulate. We illustrate these concepts with extensive computational examples; all figures presented here are reproducible using the WaveLab software package. 1}},
    author = {Coifman, R. R. and Donoho, D. L.},
    citeulike-article-id = {7343588},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.125.3682},
    keywords = {invariant, shrinkage, thresholding, translation, wavelet},
    pages = {125--150},
    posted-at = {2015-11-17 05:20:45},
    priority = {2},
    title = {{Translation-invariant de-noising}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.125.3682},
    volume = {103},
    year = {1995}
}

@article{Johnstone2005Empirical,
    author = {Johnstone, Iain M. and Silverman, Bernard W.},
    citeulike-article-id = {13839771},
    citeulike-linkout-0 = {http://dx.doi.org/10.1214/009053605000000345},
    doi = {10.1214/009053605000000345},
    issn = {0090-5364},
    journal = {The Annals of Statistics},
    keywords = {bayes, empirical, shrinkage, wavelet},
    month = aug,
    number = {4},
    pages = {1700--1752},
    posted-at = {2015-11-17 00:59:39},
    priority = {2},
    title = {{Empirical Bayes selection of wavelet thresholds}},
    url = {http://dx.doi.org/10.1214/009053605000000345},
    volume = {33},
    year = {2005}
}

@article{donoho95,
    abstract = {{We attempt to recover a function of unknown smoothness from noisy, sampled data. We introduce a procedure, SureShrink, which suppresses noise by thresholding the empirical wavelet coefficients. The thresholding is adaptive: a threshold level is assigned to each dyadic resolution level by the principle of minimizing the Stein Unbiased Estimate of Risk (Sure) for threshold estimates. The computational effort of the overall procedure is order N Δ log(N) as a function of the sample size N ....}},
    author = {Donoho, David L. and Johnstone, Iain M.},
    citeulike-article-id = {1639705},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.5188},
    journal = {Journal of the American Statistical Association},
    keywords = {shrinkage, wavelet},
    month = dec,
    number = {432},
    pages = {1200--1224},
    posted-at = {2015-11-17 00:58:46},
    priority = {2},
    title = {{Adapting to Unknown Smoothness via Wavelet Shrinkage}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.5188},
    volume = {90},
    year = {1995}
}

@article{Donoho1994Ideal,
    abstract = {{SUMMARY With ideal spatial adaptation, an oracle furnishes information about how best to adapt a spatially variable estimator, whether piecewise constant, piecewise polynomial, variable knot spline, or variable bandwidth kernel, to the unknown function. Estimation with the aid of an oracle offers dramatic advantages over traditional linear estimation by nonadaptive kernels; however, it is a priori unclear whether such performance can be obtained by a procedure relying on the data alone. We describe a new principle for spatially-adaptive estimation: selective wavelet reconstruction. We show that variable-knot spline fits and piecewise-polynomial fits, when equipped with an oracle to select the knots, are not dramatically more powerful than selective wavelet reconstruction with an oracle. We develop a practical spatially adaptive method, Risk Shrink, which works by shrinkage of empirical wavelet coefficients. RiskShrink mimics the performance of an oracle for selective wavelet reconstruction as well as it is possible to do so. A new inequality in multivariate normal decision theory which we call the oracle inequality shows that attained performance differs from ideal performance by at most a factor of approximately 2 log n, where n is the sample size. Moreover no estimator can give a better guarantee than this. Within the class of spatially adaptive procedures, RiskShrink is essentially optimal. Relying only on the data, it comes within a factor log2n of the performance of piecewise polynomial and variableknot spline methods equipped with an oracle. In contrast, it is unknown how or if piecewise polynomial methods could be made to function this well when denied access to an oracle and forced to rely on data alone.}},
    author = {Donoho, David L. and Johnstone, Jain M.},
    citeulike-article-id = {973764},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/81.3.425},
    citeulike-linkout-1 = {http://biomet.oxfordjournals.org/content/81/3/425.abstract},
    citeulike-linkout-2 = {http://biomet.oxfordjournals.org/content/81/3/425.full.pdf},
    citeulike-linkout-3 = {http://biomet.oxfordjournals.org/cgi/content/abstract/81/3/425},
    day = {01},
    doi = {10.1093/biomet/81.3.425},
    issn = {1464-3510},
    journal = {Biometrika},
    keywords = {shrinkage, spatial, wavelet},
    month = sep,
    number = {3},
    pages = {425--455},
    posted-at = {2015-11-17 00:56:51},
    priority = {2},
    publisher = {Oxford University Press},
    title = {{Ideal spatial adaptation by wavelet shrinkage}},
    url = {http://dx.doi.org/10.1093/biomet/81.3.425},
    volume = {81},
    year = {1994}
}

@article{Bickel2008Covariance,
    author = {Bickel, Peter J. and Levina, Elizaveta},
    citeulike-article-id = {10670459},
    citeulike-linkout-0 = {http://dx.doi.org/10.1214/08-aos600},
    doi = {10.1214/08-aos600},
    issn = {0090-5364},
    journal = {The Annals of Statistics},
    keywords = {covariance, shrinkage, thresholding},
    month = dec,
    number = {6},
    pages = {2577--2604},
    posted-at = {2015-11-17 00:52:40},
    priority = {2},
    title = {{Covariance regularization by thresholding}},
    url = {http://dx.doi.org/10.1214/08-aos600},
    volume = {36},
    year = {2008}
}

@article{Tibshirani1996Regression,
    abstract = {{We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.}},
    author = {Tibshirani, Robert},
    citeulike-article-id = {2453666},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2346178},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2346178},
    doi = {10.2307/2346178},
    issn = {00359246},
    journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
    keywords = {lasso, regularization, shrinkage, sparsity},
    number = {1},
    pages = {267--288},
    posted-at = {2015-11-17 00:48:34},
    priority = {2},
    publisher = {Blackwell Publishing for the Royal Statistical Society},
    title = {{Regression Shrinkage and Selection via the Lasso}},
    url = {http://dx.doi.org/10.2307/2346178},
    volume = {58},
    year = {1996}
}

@article{Menictas2015Variational,
    abstract = {{We develop fast mean field variational methodology for Bayesian heteroscedastic semiparametric regression, in which both the mean and variance are smooth, but otherwise arbitrary, functions of the predictors. Our resulting algorithms are purely algebraic, devoid of numerical integration and Monte Carlo sampling. The locality property of mean field variational Bayes implies that the methodology also applies to larger models possessing variance function components. Simulation studies indicate good to excellent accuracy, and considerable time savings compared with Markov chain Monte Carlo. We also provide some illustrations from applications.}},
    author = {Menictas, Marianne and Wand, Matt P.},
    citeulike-article-id = {13839739},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/anzs.12105},
    day = {1},
    doi = {10.1111/anzs.12105},
    journal = {Aust. N. Z. J. Stat.},
    keywords = {bayes, heteroskedastic, nonparametric, variational},
    month = mar,
    number = {1},
    pages = {119--138},
    posted-at = {2015-11-16 22:36:28},
    priority = {2},
    title = {{Variational Inference for Heteroscedastic Semiparametric Regression}},
    url = {http://dx.doi.org/10.1111/anzs.12105},
    volume = {57},
    year = {2015}
}

@article{Clyde2000Flexible,
    abstract = {{Wavelet shrinkage estimation is an increasingly popular method for signal denoising and compression. Although Bayes estimators can provide excellent mean-squared error (MSE) properties, the selection of an effective prior is a difficult task. To address this problem, we propose empirical Bayes (EB) prior selection methods for various error distributions including the normal and the heavier-tailed Student t-distributions. Under such EB prior distributions, we obtain threshold shrinkage estimators based on model selection, and multiple-shrinkage estimators based on model averaging. These EB estimators are seen to be computationally competitive with standard classical thresholding methods, and to be robust to outliers in both the data and wavelet domains. Simulated and real examples are used to illustrate the flexibility and improved MSE performance of these methods in a wide variety of settings.}},
    author = {Clyde, Merlise and George, Edward I.},
    citeulike-article-id = {13839736},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/1467-9868.00257},
    day = {1},
    doi = {10.1111/1467-9868.00257},
    journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
    keywords = {bayesian, wavelet},
    month = jan,
    number = {4},
    pages = {681--698},
    posted-at = {2015-11-16 22:12:55},
    priority = {2},
    publisher = {Blackwell Publishers Ltd.},
    title = {{Flexible empirical Bayes estimation for wavelets}},
    url = {http://dx.doi.org/10.1111/1467-9868.00257},
    volume = {62},
    year = {2000}
}

@article{Sardy1999Wavelet,
    address = {Hingham, MA, USA},
    author = {Sardy, Sylvain and Percival, Donald B. and Bruce, Andrew G. and Gao, Hong-Ye and Stuetzle, Werner},
    citeulike-article-id = {2619687},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=599302},
    issn = {0960-3174},
    journal = {Statistics and Computing},
    keywords = {unequal, wavelet},
    month = apr,
    number = {1},
    pages = {65--75},
    posted-at = {2015-11-16 22:12:34},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{Wavelet shrinkage for unequally spaced data}},
    url = {http://portal.acm.org/citation.cfm?id=599302},
    volume = {9},
    year = {1999}
}

@misc{Jacquier1994Bayesian,
    abstract = {{this article is to develop new methods for inference
and prediction in a simple class of stochastic volatility
models in which logarithm of conditional volatility follows an
autoregressive (AR) times series model. Unlike the autoregressive
conditional heteroscedasticity (ARCH) and gener-
alized ARCH (GARCH) models [see Bollerslev, Chou, and
Kroner (1992) for a survey of ARCH modeling], both the
mean and log-volatility equations have separate error terms.
The ease of evaluating the ARCH...}},
    author = {Jacquier, E. and Polson, N. and Rossi, P.},
    citeulike-article-id = {468422},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.7111},
    keywords = {time-series, volatility},
    posted-at = {2015-11-16 22:11:05},
    priority = {2},
    title = {{Bayesian analysis of stochastic volatility models}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.7111},
    year = {1994}
}

@article{Fan1998Efficient,
    abstract = {{Conditional heteroscedasticity has often been used in modelling and understanding the variability of statistical data. Under a general set-up which includes nonlinear time series models as a special case, we propose an efficient and adaptive method for estimating the conditional variance. The basic idea is to apply to local linear regression to the squared residuals. We demonstrate that, without knowing the regression function, we can estimate the conditional variance asymptotically as well as if the regression were given. This asymptotic result, established under the assumption that the observations are made from a strictly stationary and absolutely regular process, is also verified via simulation. Further, the asymptotic result paves the way for adapting an automatic bandwidth selection scheme. An application with financial data illustrates the usefulness of the proposed techniques.}},
    author = {Fan, Jianqing and Yao, Qiwei},
    citeulike-article-id = {714133},
    citeulike-linkout-0 = {http://www.jstor.org/stable/2337393},
    journal = {Biometrika},
    keywords = {nonparametric, regression, volatility},
    number = {3},
    pages = {645--660},
    posted-at = {2015-11-16 22:07:14},
    priority = {2},
    title = {{Efficient Estimation of Conditional Variance Functions in Stochastic Regression}},
    url = {http://www.jstor.org/stable/2337393},
    volume = {85},
    year = {1998}
}

@article{Johnstone1997Wavelet,
    abstract = {{Wavelet threshold estimators for data with stationary correlated noise are constructed by applying a level-dependent soft threshold to the coefficients in the wavelet transform. A variety of threshold choices is proposed, including one based on an unbiased estimate of mean-squared error. The practical performance of the method is demonstrated on examples, including data from a neurophysiological context. The theoretical properties of the estimators are investigated by comparing them with an ideal but unattainable `bench-mark', that can be considered in the wavelet context as the risk obtained by ideal spatial adaptivity, and more generally is obtained by the use of an `oracle' that provides information that is not actually available in the data. It is shown that the level-dependent threshold estimator performs well relative to the bench-mark risk, and that its minimax behaviour cannot be improved on in order of magnitude by any other estimator. The wavelet domain structure of both short- and long-range dependent noise is considered, and in both cases it is shown that the estimators have near optimal behaviour simultaneously in a wide range of function classes, adapting automatically to the regularity properties of the underlying model. The proofs of the main results are obtained by considering a more general multivariate normal decision theoretic problem.}},
    author = {Johnstone, Iain M. and Silverman, Bernard W.},
    citeulike-article-id = {13839731},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/1467-9868.00071},
    day = {1},
    doi = {10.1111/1467-9868.00071},
    journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
    keywords = {correlation, wavelet},
    month = jan,
    number = {2},
    pages = {319--351},
    posted-at = {2015-11-16 22:01:11},
    priority = {2},
    publisher = {Blackwell Publishers Ltd.},
    title = {{Wavelet Threshold Estimators for Data with Correlated Noise}},
    url = {http://dx.doi.org/10.1111/1467-9868.00071},
    volume = {59},
    year = {1997}
}

@article{Morris2006Waveletbased,
    abstract = {{Increasingly, scientific studies yield functional data, in which the ideal units of observation are curves and the observed data consist of sets of curves that are sampled on a fine grid. We present new methodology that generalizes the linear mixed model to the functional mixed model framework, with model fitting done by using a Bayesian wavelet-based approach. This method is flexible, allowing functions of arbitrary form and the full range of fixed effects structures and between-curve covariance structures that are available in the mixed model framework. It yields nonparametric estimates of the fixed and random-effects functions as well as the various between-curve and within-curve covariance matrices. The functional fixed effects are adaptively regularized as a result of the non-linear shrinkage prior that is imposed on the fixed effects' wavelet coefficients, and the random-effect functions experience a form of adaptive regularization because of the separately estimated variance components for each wavelet coefficient. Because we have posterior samples for all model quantities, we can perform pointwise or joint Bayesian inference or prediction on the quantities of the model. The adaptiveness of the method makes it especially appropriate for modelling irregular functional data that are characterized by numerous local features like peaks.}},
    author = {Morris, Jeffrey S. and Carroll, Raymond J.},
    citeulike-article-id = {542229},
    citeulike-linkout-0 = {http://www.blackwell-synergy.com/doi/abs/10.1111/j.1467-9868.2006.00539.x},
    citeulike-linkout-1 = {http://dx.doi.org/10.1111/j.1467-9868.2006.00539.x},
    citeulike-linkout-2 = {http://www.ingentaconnect.com/content/bpl/rssb/2006/00000068/00000002/art00002},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/19759841},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=19759841},
    day = {1},
    doi = {10.1111/j.1467-9868.2006.00539.x},
    issn = {1369-7412},
    journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
    keywords = {functional, regression, wavelet},
    month = apr,
    number = {2},
    pages = {179--199},
    pmid = {19759841},
    posted-at = {2015-11-16 22:00:41},
    priority = {2},
    publisher = {Blackwell Publishing},
    title = {{Wavelet-based functional mixed models}},
    url = {http://dx.doi.org/10.1111/j.1467-9868.2006.00539.x},
    volume = {68},
    year = {2006}
}

@article{Delouille2004Smooth,
    abstract = {{We treat nonparametric stochastic regression using smooth design-adapted wavelets built by means of the lifting scheme. The proposed method automatically adapts to the nature of the regression problem, that is, to the irregularity of the design, to data on the interval, and to arbitrary sample sizes (which do not need to be a power of 2). As such, this method provides a uniform solution to the usual criticisms of first-generation wavelet estimators. More precisely, starting from the unbalanced Haar basis orthogonal with respect to the empirical design measure, we use weighted average interpolation to construct biorthogonal wavelets with a higher number of vanishing analyzing moments. We include a lifting step that improves the conditioning through constrained local semiorthogonalization. We propose a wavelet thresholding algorithm and show its numerical performance both on real data and in simulations including white, correlated, and heteroscedastic noise.}},
    author = {Delouille, V. and Simoens, J. and von Sachs, R.},
    citeulike-article-id = {13839730},
    citeulike-linkout-0 = {http://dx.doi.org/10.1198/016214504000000971},
    citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1198/016214504000000971},
    day = {1},
    doi = {10.1198/016214504000000971},
    journal = {Journal of the American Statistical Association},
    keywords = {wavelet},
    month = sep,
    number = {467},
    pages = {643--658},
    posted-at = {2015-11-16 21:59:00},
    priority = {2},
    publisher = {Taylor \& Francis},
    title = {{Smooth Design-Adapted Wavelets for Nonparametric Stochastic Regression}},
    url = {http://dx.doi.org/10.1198/016214504000000971},
    volume = {99},
    year = {2004}
}

@article{Silverman1999Wavelets,
    abstract = {{The original application of wavelets in statistics was to the estimation of a curve given observations of the curve plus white noise at 2<sup>J</sup> regularly spaced points. The rationale for the use of wavelet methods in this context is reviewed briefly. Various extensions of the standard statistical methodology are discussed. These include curve estimation in the presence of correlated and non-stationary noise, the estimation of (0-1) functions, the handling of irregularly spaced data and data with heavy-tailed noise, and deformable templates in image and shape analysis. Important tools are a Bayesian approach, where a suitable prior is placed on the wavelet expansion, encapsulating the notion that most of the wavelet coefficients are zero; the use of the non-decimated, or translation-invariant, wavelet transform; and a fast algorithm for finding all the within-level covariances within the table of wavelet coefficients of a sequence with arbitrary band-limited covariance structure. Practical applications drawn from neurophysiology, meteorology and palaeopathology are presented. Finally, some directions for possible future research are outlined.}},
    author = {Silverman, Bernard W.},
    citeulike-article-id = {7364983},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/55173},
    citeulike-linkout-1 = {http://www.jstor.org/stable/55173},
    doi = {10.2307/55173},
    issn = {1364503X},
    journal = {Philosophical Transactions: Mathematical, Physical and Engineering Sciences},
    keywords = {nonstandard, wavelet},
    number = {1760},
    pages = {2459--2473},
    posted-at = {2015-11-16 21:58:27},
    priority = {2},
    publisher = {The Royal Society},
    title = {{Wavelets in Statistics: Beyond the Standard Assumptions}},
    url = {http://dx.doi.org/10.2307/55173},
    volume = {357},
    year = {1999}
}

@article{Gao1997Wavelet,
    abstract = {{We study the following heteroscedastic nonparametric regression model:  y i = f(t i ) + oe(t i )z i  where fz i g is independent identically distributed random noise with z i \^{A}¸ N(0; 1) and oe  2  (t) is the variance function. We want to estimate f . We extend Donoho and Johnstone's wavelet shrinkage technique (known as WaveShrink) to this model. We address the issue of variance estimation and propose a procedure based on non-decimated wavelet transform and running MAD (Median Absolute Deviation from the median).  Key Words and Phrases: Heteroscedasticity; Nonparametric Regression; Running MAD; Wavelet Transform; Variance Estimation; 1 Introduction  Suppose we observe data y = (y 1 ; : : : ; y n )  0  given by  y i = f(t i ) + " i i = 1; 2; :::; n (1) with t i = (i \Gamma 1)=n and f" i g drawn from some noisy process. The unknown function f is potentially complex, spatially inhomogeneous. Our goal is to estimate f = (f 1 ; : : : ; f n )  0  with small mean-square-error (L 2 risk):  R(  ...}},
    author = {Gao, Hong-ye},
    citeulike-article-id = {13839729},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.6244},
    keywords = {heteroskedastic, wavelet1},
    posted-at = {2015-11-16 21:57:10},
    priority = {2},
    title = {{Wavelet Shrinkage Estimates For Heteroscedastic Regression Models}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.6244},
    year = {1997}
}

@article{cai01,
    abstract = {{In standard wavelet methods, the empirical wavelet coefficients are thresholded term by term, on the basis of their individual magnitudes. Information on other coefficients has no influence on the treatment of particular coefficients. We propose a wavelet shrinkage method that incorporates information on neighboring coefficients into the decision making. The coefficients are considered in overlapping blocks; the treatment of coefficients in the middle of each block depends on the data in the...}},
    author = {Cai, T. T. and Silverman, B. W.},
    citeulike-article-id = {1639284},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.6312},
    journal = {Sankhya B},
    keywords = {neighblock, wavelet},
    number = {63},
    pages = {127--148},
    posted-at = {2015-11-16 21:55:59},
    priority = {2},
    title = {{Incorporating Information on Neighboring Coefficients into Wavelet Estimation}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.6312},
    year = {2001}
}

@article{Wang2013Full,
    abstract = {{In this paper, we introduce a new Bayesian nonparametric model for estimating an unknown function in the presence of Gaussian noise. The proposed model involves a mixture of a point mass and an arbitrary (nonparametric) symmetric and unimodal distribution for modeling wavelet coefficients. Posterior simulation uses slice sampling ideas and the consistency under the proposed model is discussed. In particular, the method is shown to be computationally competitive with some of best Empirical wavelet estimation methods.}},
    author = {Wang, Xue and Walker, Stephen G.},
    citeulike-article-id = {11249835},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jspi.2012.05.010},
    doi = {10.1016/j.jspi.2012.05.010},
    issn = {03783758},
    journal = {Journal of Statistical Planning and Inference},
    keywords = {bayesian, wavelet},
    month = jan,
    number = {1},
    pages = {55--62},
    posted-at = {2015-11-16 21:51:09},
    priority = {2},
    title = {{Full Bayesian wavelet inference with a nonparametric prior}},
    url = {http://dx.doi.org/10.1016/j.jspi.2012.05.010},
    volume = {143},
    year = {2013}
}

@article{Wang2010Penalised,
    abstract = {{In this paper we propose a simple Bayesian block wavelet shrinkage method for estimating an unknown function in the presence of Gaussian noise. A data-driven procedure which can adaptively choose the block size and the shrinkage level at each resolution level is provided. The asymptotic property of the proposed method, BBN (Bayesian BlockNorm shrinkage), is investigated in the Besov sequence space. The numerical performance and comparisons with some of existing wavelet denoising methods show that the new method can achieve good performance but with the least computational time.}},
    author = {Wang, Xue and Walker, Stephen G.},
    citeulike-article-id = {6833228},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.spl.2010.02.013},
    day = {08},
    doi = {10.1016/j.spl.2010.02.013},
    issn = {01677152},
    journal = {Statistics \& Probability Letters},
    keywords = {bayesian, wavelet},
    month = jun,
    number = {11-12},
    pages = {990--996},
    posted-at = {2015-11-16 21:50:33},
    priority = {2},
    title = {{A penalised data-driven block shrinkage approach to empirical Bayes wavelet estimation}},
    url = {http://dx.doi.org/10.1016/j.spl.2010.02.013},
    volume = {80},
    year = {2010}
}

@article{Rivoirard2004Thresholding,
    author = {Rivoirard, Vincent},
    booktitle = {Test},
    citeulike-article-id = {13839727},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/bf02603007},
    citeulike-linkout-1 = {http://link.springer.com/article/10.1007/BF02603007},
    doi = {10.1007/bf02603007},
    keywords = {bayesian, wavelet},
    number = {1},
    pages = {213--246},
    posted-at = {2015-11-16 21:49:53},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {{Thresholding procedure with priors based on Pareto distributions}},
    url = {http://dx.doi.org/10.1007/bf02603007},
    volume = {13},
    year = {2004}
}

@article{Wang2006Empirical,
    abstract = {{Empirical Bayes approaches to the shrinkage of empirical wavelet coefficients have generated considerable interest in recent years. Much of the work to date has focussed on shrinkage of individual wavelet coefficients in isolation. In this paper we propose an empirical Bayes approach to simultaneous shrinkage of wavelet coefficients in a block, based on the block sum of squares. Our approach exploits a useful identity satisfied by the noncentral χ2 density and provides some tractable Bayesian block shrinkage procedures. Our numerical results indicate that the new procedures perform very well.}},
    author = {Wang, Xue and Wood, Andrew T. A.},
    citeulike-article-id = {895140},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/93.3.705},
    citeulike-linkout-1 = {http://biomet.oxfordjournals.org/content/93/3/705.abstract},
    citeulike-linkout-2 = {http://biomet.oxfordjournals.org/content/93/3/705.full.pdf},
    citeulike-linkout-3 = {http://www.ingentaconnect.com/content/oup/biomet/2006/00000093/00000003/art00705},
    day = {01},
    doi = {10.1093/biomet/93.3.705},
    issn = {1464-3510},
    journal = {Biometrika},
    keywords = {bayesian, wavelet},
    month = sep,
    number = {3},
    pages = {705--722},
    posted-at = {2015-11-16 21:49:31},
    priority = {2},
    publisher = {Oxford University Press},
    title = {{Empirical Bayes block shrinkage of wavelet coefficients via the noncentral χ2 distribution}},
    url = {http://dx.doi.org/10.1093/biomet/93.3.705},
    volume = {93},
    year = {2006}
}

@article{Cai2008Adaptive,
    author = {Cai, Tony T. and Wang, Lie},
    citeulike-article-id = {13839726},
    citeulike-linkout-0 = {http://dx.doi.org/10.1214/07-aos509},
    doi = {10.1214/07-aos509},
    issn = {0090-5364},
    journal = {The Annals of Statistics},
    keywords = {heteroskedastic, wavelet},
    month = oct,
    number = {5},
    pages = {2025--2054},
    posted-at = {2015-11-16 21:48:49},
    priority = {2},
    title = {{Adaptive variance function estimation in heteroscedastic nonparametric regression}},
    url = {http://dx.doi.org/10.1214/07-aos509},
    volume = {36},
    year = {2008}
}

@electronic{Wang2008Effect,
    abstract = {{Variance function estimation in nonparametric regression is considered and
the minimax rate of convergence is derived. We are particularly interested in
the effect of the unknown mean on the estimation of the variance function. Our
results indicate that, contrary to the common practice, it is not desirable to
base the estimator of the variance function on the residuals from an optimal
estimator of the mean when the mean function is not smooth. Instead it is more
desirable to use estimators of the mean with minimal bias. On the other hand,
when the mean function is very smooth, our numerical results show that the
residual-based method performs better, but not substantial better than the
first-order-difference-based estimator. In addition our asymptotic results also
correct the optimal rate claimed in Hall and Carroll [J. Roy. Statist. Soc.
Ser. B 51 (1989) 3--14].}},
    archivePrefix = {arXiv},
    author = {Wang, Lie and Brown, Lawrence D. and Cai, Tony T. and Levine, Michael},
    citeulike-article-id = {2729144},
    citeulike-linkout-0 = {http://arxiv.org/abs/0804.0709},
    citeulike-linkout-1 = {http://arxiv.org/pdf/0804.0709},
    day = {4},
    eprint = {0804.0709},
    keywords = {heteroskedastic, wavelet},
    month = apr,
    posted-at = {2015-11-16 21:48:16},
    priority = {2},
    title = {{Effect of mean on variance function estimation in nonparametric regression}},
    url = {http://arxiv.org/abs/0804.0709},
    year = {2008}
}

@article{Brown2007Variance,
    author = {Brown, Lawrence D. and Levine, M.},
    citeulike-article-id = {13839720},
    citeulike-linkout-0 = {http://dx.doi.org/10.1214/009053607000000145},
    doi = {10.1214/009053607000000145},
    issn = {0090-5364},
    journal = {The Annals of Statistics},
    keywords = {heteroskedastic, nonparametric},
    month = oct,
    number = {5},
    pages = {2219--2232},
    posted-at = {2015-11-16 21:45:04},
    priority = {2},
    title = {{Variance estimation in nonparametric regression via the difference sequence method}},
    url = {http://dx.doi.org/10.1214/009053607000000145},
    volume = {35},
    year = {2007}
}

@inproceedings{Lefkimmiatis2009PoissonHaar,
    author = {Lefkimmiatis, Stamatios and Papandreou, George and Maragos, Petros},
    booktitle = {Image Processing (ICIP), 2009 16th IEEE International Conference on},
    citeulike-article-id = {13839715},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icip.2009.5414053},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5414053},
    doi = {10.1109/icip.2009.5414053},
    institution = {Sch. of ECE, Nat. Tech. Univ. of Athens, Athens, Greece},
    isbn = {978-1-4244-5653-6},
    issn = {1522-4880},
    keywords = {multiscale, poisson},
    month = nov,
    pages = {3853--3856},
    posted-at = {2015-11-16 21:40:40},
    priority = {2},
    publisher = {IEEE},
    title = {{Poisson-Haar Transform: A nonlinear multiscale representation for photon-limited image denoising}},
    url = {http://dx.doi.org/10.1109/icip.2009.5414053},
    year = {2009}
}

@article{Horn1975Comparison,
    abstract = {{Abstract Four methods for estimating heteroscedastic variances are discussed in this article: the MINQUE introduced by C.R. Rao [7], the AUE introduced by S.D. Horn, R.A. Horn, and D.B. Duncan [4], the average of the squared residuals, and the sample variance. Properties of these estimators, including translation invariance, existence, bias, consistency, existence of negative estimates, and mean square error (MSE) are compared. In particular, it is shown that the AUE has smaller MSE than either the MINQUE or the sample variance in a wide range of situations. Abstract Four methods for estimating heteroscedastic variances are discussed in this article: the MINQUE introduced by C.R. Rao [7], the AUE introduced by S.D. Horn, R.A. Horn, and D.B. Duncan [4], the average of the squared residuals, and the sample variance. Properties of these estimators, including translation invariance, existence, bias, consistency, existence of negative estimates, and mean square error (MSE) are compared. In particular, it is shown that the AUE has smaller MSE than either the MINQUE or the sample variance in a wide range of situations.}},
    author = {Horn, Susan D. and Horn, Roger A.},
    citeulike-article-id = {13839708},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.1975.10480316},
    citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1975.10480316},
    day = {1},
    doi = {10.1080/01621459.1975.10480316},
    journal = {Journal of the American Statistical Association},
    keywords = {heteroskedastic, linear},
    month = dec,
    number = {352},
    pages = {872--879},
    posted-at = {2015-11-16 21:31:32},
    priority = {2},
    publisher = {Taylor \& Francis},
    title = {{Comparison of Estimators of Heteroscedastic Variances in Linear Models}},
    url = {http://dx.doi.org/10.1080/01621459.1975.10480316},
    volume = {70},
    year = {1975}
}

@article{Antoniadis2001Wavelet,
    author = {Antoniadis, Anestis and Bigot, J\'{e}r\'{e}mie and Sapatinas, Theofanis},
    citeulike-article-id = {13839704},
    citeulike-linkout-0 = {http://dx.doi.org/10.18637/jss.v006.i06},
    doi = {10.18637/jss.v006.i06},
    issn = {1548-7660},
    journal = {Journal of Statistical Software},
    keywords = {simulation, wavelet},
    number = {6},
    posted-at = {2015-11-16 21:30:02},
    priority = {2},
    title = {{Wavelet Estimators in Nonparametric Regression: A Comparative Simulation Study}},
    url = {http://dx.doi.org/10.18637/jss.v006.i06},
    volume = {6},
    year = {2001}
}

@article{Antoniadis2001Exp,
    abstract = {{We propose a wavelet shrinkage methodology for univariate natural exponential families with quadratic variance functions, covering the Gaussian, Poisson, gamma, binomial, negative binomial and generalised hyperbolic secant distributions. Simulation studies for Poisson and binomial data are used to illustrate the usefulness of the proposed methodology, and comparisons are made with other methods available in the literature. We also present applications to datasets arising from high‐energy astrophysics and from epidemiology.}},
    author = {Antoniadis, Anestis and Sapatinas, Theofanis},
    citeulike-article-id = {13839702},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/88.3.805},
    citeulike-linkout-1 = {http://biomet.oxfordjournals.org/content/88/3/805.abstract},
    citeulike-linkout-2 = {http://biomet.oxfordjournals.org/content/88/3/805.full.pdf},
    day = {01},
    doi = {10.1093/biomet/88.3.805},
    issn = {1464-3510},
    journal = {Biometrika},
    keywords = {exponential, family, wavelet},
    month = oct,
    number = {3},
    pages = {805--820},
    posted-at = {2015-11-16 21:27:51},
    priority = {2},
    publisher = {Oxford University Press},
    title = {{Wavelet shrinkage for natural exponential families with quadratic variance functions}},
    url = {http://dx.doi.org/10.1093/biomet/88.3.805},
    volume = {88},
    year = {2001}
}

@article{Antoniadis2007Poisson,
    abstract = {{In this paper we focus on nonparametric estimators in inverse problems for
Poisson processes involving the use of wavelet decompositions. Adopting an
adaptive wavelet Galerkin discretization, we find that our method combines the
well-known theoretical advantages of wavelet--vaguelette decompositions for
inverse problems in terms of optimally adapting to the unknown smoothness of
the solution, together with the remarkably simple closed-form expressions of
Galerkin inversion methods. Adapting the results of Barron and Sheu [Ann.
Statist. 19 (1991) 1347--1369] to the context of log-intensity functions
approximated by wavelet series with the use of the Kullback--Leibler distance
between two point processes, we also present an asymptotic analysis of
convergence rates that justifies our approach. In order to shed some light on
the theoretical results obtained and to examine the accuracy of our estimates
in finite samples, we illustrate our method by the analysis of some simulated
examples.}},
    archivePrefix = {arXiv},
    author = {Antoniadis, Anestis and Bigot, J\'{e}remie},
    citeulike-article-id = {13839701},
    citeulike-linkout-0 = {http://arxiv.org/abs/math/0601099.pdf},
    citeulike-linkout-1 = {http://arxiv.org/pdf/math/0601099.pdf},
    citeulike-linkout-2 = {http://dx.doi.org/10.1214/009053606000000687},
    day = {22},
    doi = {10.1214/009053606000000687},
    eprint = {math/0601099.pdf},
    issn = {0090-5364},
    journal = {The Annals of Statistics},
    keywords = {multiscale, poisson},
    month = feb,
    number = {5},
    pages = {2132--2158},
    posted-at = {2015-11-16 21:27:29},
    priority = {2},
    title = {{Poisson inverse problems}},
    url = {http://dx.doi.org/10.1214/009053606000000687},
    volume = {34},
    year = {2007}
}

@article{Nowak2000Statistical,
    author = {Nowak, Robert D. and Kolaczyk, Eric D.},
    citeulike-article-id = {13839696},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/18.857793},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=857793},
    doi = {10.1109/18.857793},
    institution = {Dept. of Electr. \& Comput. Eng., Rice Univ., Houston, TX, USA},
    issn = {0018-9448},
    journal = {Information Theory, IEEE Transactions on},
    keywords = {multiscale, poisson},
    month = aug,
    number = {5},
    pages = {1811--1825},
    posted-at = {2015-11-16 21:23:27},
    priority = {2},
    publisher = {IEEE},
    title = {{A statistical multiscale framework for Poisson inverse problems}},
    url = {http://dx.doi.org/10.1109/18.857793},
    volume = {46},
    year = {2000}
}

@incollection{Nowak1999Multiscale,
    author = {Nowak, Robert D.},
    booktitle = {Bayesian Inference in Wavelet-Based Models},
    citeulike-article-id = {13839691},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-1-4612-0567-8_16},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-1-4612-0567-8_16},
    doi = {10.1007/978-1-4612-0567-8_16},
    editor = {M\"{u}ller, Peter and Vidakovic, Brani},
    keywords = {multiscale, poisson},
    pages = {243--265},
    posted-at = {2015-11-16 21:04:21},
    priority = {2},
    publisher = {Springer New York},
    series = {Lecture Notes in Statistics},
    title = {{Multiscale Hidden Markov Models for Bayesian Image Analysis}},
    url = {http://dx.doi.org/10.1007/978-1-4612-0567-8_16},
    volume = {141},
    year = {1999}
}

@article{Lefkimmiatis2009Bayesian,
    abstract = {{We present an improved statistical model for analyzing Poisson processes, with applications to photon-limited imaging. We build on previous work, adopting a multiscale representation of the Poisson process in which the ratios of the underlying Poisson intensities (rates) in adjacent scales are modeled as mixtures of conjugate parametric distributions. Our main contributions include: 1) a rigorous and robust regularized expectation-maximization (EM) algorithm for maximum-likelihood estimation of the rate-ratio density parameters directly from the noisy observed Poisson data (counts); 2) extension of the method to work under a multiscale hidden Markov tree model (HMT) which couples the mixture label assignments in consecutive scales, thus modeling interscale coefficient dependencies in the vicinity of image edges; 3) exploration of a 2-D recursive quad-tree image representation, involving Dirichlet-mixture rate-ratio densities, instead of the conventional separable binary-tree image representation involving beta-mixture rate-ratio densities; and 4) a novel multiscale image representation, which we term Poisson-Haar decomposition, that better models the image edge structure, thus yielding improved performance. Experimental results on standard images with artificially simulated Poisson noise and on real photon-limited images demonstrate the effectiveness of the proposed techniques.}},
    address = {Piscataway, NJ, USA},
    author = {Lefkimmiatis, Stamatios and Maragos, Petros and Papandreou, George},
    citeulike-article-id = {7466027},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1657340.1657344},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/tip.2009.2022008},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4907062},
    doi = {10.1109/tip.2009.2022008},
    institution = {Sch. of Electr. \& Comput. Eng., Nat. Tech. Univ. of Athens, Athens, Greece},
    issn = {1057-7149},
    journal = {Image Processing, IEEE Transactions on},
    keywords = {multiscale, poisson},
    month = aug,
    number = {8},
    pages = {1724--1741},
    posted-at = {2015-11-16 21:03:15},
    priority = {2},
    publisher = {IEEE},
    title = {{Bayesian Inference on Multiscale Models for Poisson Intensity Estimation: Applications to Photon-Limited Image Denoising}},
    url = {http://dx.doi.org/10.1109/tip.2009.2022008},
    volume = {18},
    year = {2009}
}

@misc{Nason2013Bayesian,
    abstract = {{It is increasingly being realised that many real world time series are not
stationary and exhibit evolving second-order autocovariance or spectral
structure. This article introduces a Bayesian approach for modelling the
evolving wavelet spectrum of a locally stationary wavelet time series. Our new
method works by combining the advantages of a Haar-Fisz transformed spectrum
with a simple, but powerful, Bayesian wavelet shrinkage method. Our new method
produces excellent and stable spectral estimates and this is demonstrated via
simulated data and on differenced infant ECG data. A major additional benefit
of the Bayesian paradigm is that we obtain rigorous and useful credible
intervals of the evolving spectral structure. We show how the Bayesian credible
intervals provide extra insight into the infant ECG data.}},
    archivePrefix = {arXiv},
    author = {Nason, Guy P. and Stevens, Kara N.},
    citeulike-article-id = {13839651},
    citeulike-linkout-0 = {http://arxiv.org/abs/1309.2435v1.pdf},
    citeulike-linkout-1 = {http://arxiv.org/pdf/1309.2435v1.pdf},
    day = {10},
    eprint = {1309.2435v1.pdf},
    keywords = {fisz, haar, poisson, wavelet},
    month = sep,
    posted-at = {2015-11-16 19:32:37},
    priority = {2},
    title = {{Bayesian Wavelet Shrinkage of the Haar-Fisz Transformed Wavelet Periodogram}},
    url = {http://arxiv.org/abs/1309.2435v1.pdf},
    year = {2013}
}

@article{Kolaczyk2004Multiscale,
    abstract = {{We describe here a framework for a certain class of multiscale likelihood
factorizations wherein, in analogy to a wavelet decomposition of an L^2
function, a given likelihood function has an alternative representation as a
product of conditional densities reflecting information in both the data and
the parameter vector localized in position and scale. The framework is
developed as a set of sufficient conditions for the existence of such
factorizations, formulated in analogy to those underlying a standard
multiresolution analysis for wavelets, and hence can be viewed as a
multiresolution analysis for likelihoods. We then consider the use of these
factorizations in the task of nonparametric, complexity penalized likelihood
estimation. We study the risk properties of certain thresholding and
partitioning estimators, and demonstrate their adaptivity and near-optimality,
in a minimax sense over a broad range of function spaces, based on squared
Hellinger distance as a loss function. In particular, our results provide an
illustration of how properties of classical wavelet-based estimators can be
obtained in a single, unified framework that includes models for continuous,
count and categorical data types.}},
    archivePrefix = {arXiv},
    author = {Kolaczyk, Eric D. and Nowak, Robert D.},
    citeulike-article-id = {13839650},
    citeulike-linkout-0 = {http://arxiv.org/abs/math/0406424.pdf},
    citeulike-linkout-1 = {http://arxiv.org/pdf/math/0406424.pdf},
    citeulike-linkout-2 = {http://dx.doi.org/10.1214/009053604000000076},
    day = {22},
    doi = {10.1214/009053604000000076},
    eprint = {math/0406424.pdf},
    issn = {0090-5364},
    journal = {The Annals of Statistics},
    keywords = {multiscale, poisson},
    month = jun,
    number = {2},
    pages = {500--527},
    posted-at = {2015-11-16 19:32:22},
    priority = {2},
    title = {{Multiscale likelihood analysis and complexity penalized estimation}},
    url = {http://dx.doi.org/10.1214/009053604000000076},
    volume = {32},
    year = {2004}
}

@article{Hirakawa2012Skellam,
    author = {Hirakawa, Keigo and Wolfe, Patrick J.},
    citeulike-article-id = {13839649},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tit.2011.2165933},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6017201},
    doi = {10.1109/tit.2011.2165933},
    institution = {Intell. Signal Syst. Lab., Univ. of Dayton, Dayton, OH, USA},
    issn = {0018-9448},
    journal = {Information Theory, IEEE Transactions on},
    keywords = {multiscale, poisson, skellam},
    month = feb,
    number = {2},
    pages = {1080--1093},
    posted-at = {2015-11-16 19:32:05},
    priority = {2},
    publisher = {IEEE},
    title = {{Skellam Shrinkage: Wavelet-Based Intensity Estimation for Inhomogeneous Poisson Data}},
    url = {http://dx.doi.org/10.1109/tit.2011.2165933},
    volume = {58},
    year = {2012}
}

@article{Fryzlewicz2004HaarFisz,
    abstract = {{This article introduces a new method for the estimation of the intensity of an inhomogeneous one-dimensional Poisson process. The Haar-Fisz transformation transforms a vector of binned Poisson counts to approximate normality with variance one. Hence we can use any suitable Gaussian wavelet shrinkage method to estimate the Poisson intensity. Since the Haar-Fisz operator does not commute with the shift operator we can dramatically improve accuracy by always cycle spinning before the Haar-Fisz transform as well as optionally after. Extensive simulations show that our approach usually significantly outperformed state-of-the-art competitors but was occasionally comparable. Our method is fast, simple, automatic, and easy to code. Our technique is applied to the estimation of the intensity of earthquakes in northern California. We show that our technique gives visually similar results to the current state-of-the-art.}},
    author = {Fryzlewicz, Piotr and Nason, Guy P.},
    citeulike-article-id = {13839648},
    citeulike-linkout-0 = {http://dx.doi.org/10.1198/106186004x2697},
    citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1198/106186004X2697},
    day = {1},
    doi = {10.1198/106186004x2697},
    journal = {Journal of Computational and Graphical Statistics},
    month = sep,
    number = {3},
    pages = {621--638},
    posted-at = {2015-11-16 19:31:48},
    priority = {2},
    publisher = {Taylor \& Francis},
    title = {{A Haar-Fisz Algorithm for Poisson Intensity Estimation}},
    url = {http://dx.doi.org/10.1198/106186004x2697},
    volume = {13},
    year = {2004}
}

@article{Besbeas2004Comparative,
    abstract = {{Using computer simulations, the finite sample performance of a number of classical and Bayesian wavelet shrinkage estimators for Poisson counts is examined. For the purpose of comparison, a variety of intensity functions, background intensity levels, sample sizes, primary resolution levels, wavelet filters and performance criteria are employed. A demonstration is given of the use of some of the estimators to analyse a data set arising in high-energy astrophysics. Following the philosophy of reproducible research, the Matlab programs and real-life data example used in this study are made freely available. Nous \'{e}tudions l'aide de simulations num\'{e}riques, le comportement \`{a} taille d'\'{e}chantillon fini d'un certain nombre d'estimateurs de l'intensit\'{e} de comptages Poissonniens, fond\'{e}s sur des proc\'{e}dures de seuillage, classiques et bayesiennes, des coefficients d'ondelettes. A cet effet nous employons une large gamme de fonctions d'intensit\'{e}, de bruit de fond, de tailles d'\'{e}chantillons, de r\'{e}solution primaire de d\'{e}composition et de famille d'ondelettes et des crit\`{e}res de performance vari\'{e}s. Les m\'{e}thodes sont illustr\'{e}es sur un exemple r\'{e}el issus d'astrophysique. Selon les principes d'une recherche reproductible les proc\'{e}dures Matlab et les exemples trait\'{e}s sont gracieusement disponibles.}},
    author = {Besbeas, Panagiotis and De Feis, Italia and Sapatinas, Theofanis},
    citeulike-article-id = {13839645},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1751-5823.2004.tb00234.x},
    day = {1},
    doi = {10.1111/j.1751-5823.2004.tb00234.x},
    journal = {International Statistical Review},
    keywords = {multiscale, poisson, simulation, wavelet},
    month = aug,
    number = {2},
    pages = {209--237},
    posted-at = {2015-11-16 19:31:05},
    priority = {2},
    publisher = {Blackwell Publishing Ltd},
    title = {{A Comparative Simulation Study of Wavelet Shrinkage Estimators for Poisson Counts}},
    url = {http://dx.doi.org/10.1111/j.1751-5823.2004.tb00234.x},
    volume = {72},
    year = {2004}
}

@article{Jansen2006Multiscale,
    abstract = {{Summary.  The paper introduces a framework for non-linear multiscale decompositions of Poisson data that have piecewise smooth intensity curves. The key concept is conditioning on the sum of the observations that are involved in the computation of a given multiscale coefficient. Within this framework, most classical wavelet thresholding schemes for data with additive homoscedastic noise can be used. Any family of wavelet transforms (orthogonal, biorthogonal or second generation) can be incorporated in this framework. Our second contribution is to propose a Bayesian shrinkage approach with an original prior for coefficients of this decomposition. As such, the method combines the advantages of the Haar–Fisz transform with wavelet smoothing and (Bayesian) multiscale likelihood models, with additional benefits, such as extendability towards arbitrary wavelet families. Simulations show an important reduction in average squared error of the output, compared with the present techniques of Anscombe or Fisz variance stabilization or multiscale likelihood modelling.}},
    author = {Jansen, Maarten},
    citeulike-article-id = {448083},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1467-9868.2005.00531.x},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/bpl/rssb/2006/00000068/00000001/art00003},
    day = {1},
    doi = {10.1111/j.1467-9868.2005.00531.x},
    issn = {1369-7412},
    journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
    keywords = {multiscale, poisson},
    month = feb,
    number = {1},
    pages = {27--48},
    posted-at = {2015-11-16 19:30:39},
    priority = {2},
    publisher = {Blackwell Publishing Ltd},
    title = {{Multiscale Poisson data smoothing}},
    url = {http://dx.doi.org/10.1111/j.1467-9868.2005.00531.x},
    volume = {68},
    year = {2006}
}

@article{Harmany2011This,
    abstract = {{The observations in many applications consist of counts of discrete events,
such as photons hitting a detector, which cannot be effectively modeled using
an additive bounded or Gaussian noise model, and instead require a Poisson
noise model. As a result, accurate reconstruction of a spatially or temporally
distributed phenomenon (f*) from Poisson data (y) cannot be effectively
accomplished by minimizing a conventional penalized least-squares objective
function. The problem addressed in this paper is the estimation of f* from y in
an inverse problem setting, where (a) the number of unknowns may potentially be
larger than the number of observations and (b) f* admits a sparse
approximation. The optimization formulation considered in this paper uses a
penalized negative Poisson log-likelihood objective function with nonnegativity
constraints (since Poisson intensities are naturally nonnegative). In
particular, the proposed approach incorporates key ideas of using separable
quadratic approximations to the objective function at each iteration and
penalization terms related to l1 norms of coefficient vectors, total variation
seminorms, and partition-based multiscale estimation methods.}},
    archivePrefix = {arXiv},
    author = {Harmany, Zachary T. and Marcia, Roummel F. and Willett, Rebecca M.},
    citeulike-article-id = {13839643},
    citeulike-linkout-0 = {http://arxiv.org/abs/1005.4274.pdf},
    citeulike-linkout-1 = {http://arxiv.org/pdf/1005.4274.pdf},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/tip.2011.2168410},
    day = {12},
    doi = {10.1109/tip.2011.2168410},
    eprint = {1005.4274.pdf},
    issn = {1057-7149},
    journal = {IEEE Transactions on Image Processing},
    keywords = {poisson},
    month = oct,
    number = {3},
    pages = {1084--1096},
    posted-at = {2015-11-16 19:28:21},
    priority = {2},
    title = {{This is SPIRAL-TAP: Sparse Poisson Intensity Reconstruction ALgorithms - Theory and Practice}},
    url = {http://dx.doi.org/10.1109/tip.2011.2168410},
    volume = {21},
    year = {2011}
}

@article{Gart1967Bias,
    author = {Gart, J. J. and Zweifel, J. R.},
    citeulike-article-id = {13415878},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/6049534},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=6049534},
    issn = {0006-3444},
    journal = {Biometrika},
    keywords = {binomial, likelihood, logistic},
    month = jun,
    number = {1},
    pages = {181--187},
    pmid = {6049534},
    posted-at = {2015-11-16 19:23:05},
    priority = {2},
    title = {{On the bias of various estimators of the logit and its variance with application to quantal bioassay.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/6049534},
    volume = {54},
    year = {1967}
}

@article{Fryzlewicz2008Datadriven,
    author = {Fryzlewicz, Piotr},
    citeulike-article-id = {13839641},
    citeulike-linkout-0 = {http://dx.doi.org/10.1214/07-ejs139},
    doi = {10.1214/07-ejs139},
    issn = {1935-7524},
    journal = {Electronic Journal of Statistics},
    keywords = {fisz, haar, poisson},
    number = {0},
    pages = {863--896},
    posted-at = {2015-11-16 19:21:05},
    priority = {2},
    title = {{Data-driven wavelet-Fisz methodology for nonparametric function estimation}},
    url = {http://dx.doi.org/10.1214/07-ejs139},
    volume = {2},
    year = {2008}
}

@article{Beylkin1992Representation,
    address = {Philadelphia, PA, USA},
    author = {Beylkin, G.},
    citeulike-article-id = {758859},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=139911},
    citeulike-linkout-1 = {http://dx.doi.org/10.1137/0729097},
    doi = {10.1137/0729097},
    issn = {0036-1429},
    journal = {SIAM J. Numer. Anal.},
    keywords = {circulant, invariant, shift, shrinkage, thresholding, translation, wavelet},
    month = dec,
    number = {6},
    pages = {1716--1740},
    posted-at = {2015-11-24 17:50:06},
    priority = {2},
    publisher = {Society for Industrial and Applied Mathematics},
    title = {{On the representation of operators in bases of compactly supported wavelets}},
    url = {http://dx.doi.org/10.1137/0729097},
    volume = {29},
    year = {1992}
}

@inproceedings{D93,
    abstract = {{. We describe wavelet methods for recovery of objects from noisy and incomplete data. The common themes: (a) the new methods utilize nonlinear operations in the wavelet domain; (b) they accomplish tasks which are not possible by traditional linear/Fourier approaches to such problems. We attempt to indicate the heuristic principles, theoretical foundations, and possible application areas for these methods. Areas covered: (1) Wavelet De-Noising. (2) Wavelet Approaches to Linear Inverse Problems. (4) Wavelet Packet De-Noising. (5) Segmented MultiResolutions. (6) Nonlinear Multi-resolutions. 1. Introduction.  With the rapid development of computerized scientific instruments comes a wide variety of interesting problems for data analysis and signal processing. In fields ranging from Extragalactic Astronomy to Molecular Spectroscopy to Medical Imaging to Computer Vision, one must recover a signal, curve, image, spectrum, or density from incomplete, indirect, and noisy data. What can wavelets ...}},
    author = {Donoho, David L.},
    booktitle = {In Proceedings of Symposia in Applied Mathematics},
    citeulike-article-id = {9268342},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.7262},
    keywords = {poisson, regression, shrinkage, thresholding, vst, wavelet},
    pages = {173--205},
    posted-at = {2016-01-08 22:35:49},
    priority = {2},
    publisher = {AMS},
    title = {{Nonlinear Wavelet Methods for Recovery of Signals, Densities, and Spectra from Indirect and Noisy Data}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.7262},
    volume = {47},
    year = {1993}
}

@article{kolaczyk1999wavelet,
  title={Wavelet shrinkage estimation of certain Poisson intensity signals using corrected thresholds},
  author={Kolaczyk, Eric D},
  journal={Statistica Sinica},
  volume={9},
  number={1},
  pages={119--135},
  year={1999},
  publisher={C/O DR HC HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN}
}


@inproceedings{Kolaczyk1996NonParametric,
    abstract = {{In this article, I present a method for the non-parametric (model-free) estimation of intensity profiles underlying gamma-ray bursts. The method, TIPSH, is based on applying specially calibrated thresholds to the Haar wavelet coefficients of binned counts gathered from such bursts. As functions well-localized with respect to both time and scale, wavelets are an ideal tool for working with the often sharp, abrupt nature of gamma-ray burst signals. When applied to an idealized signal in a small simulation study and a selection of actual gamma-ray bursts, the TIPSH algorithm is found to be well capable of simultaneously estimating the smooth, uniform background and the pulse-like structure of gamma-ray burst signals.  Subject headings: gamma rays: bursts -- methods: statistical  1 INTRODUCTION.  In this paper I introduce a non-parametric method for estimating the intensity profiles of gamma-ray bursts (GRBs). The term `non-parametric' is used in the statistical sense, to refer to a lack ...}},
    author = {Kolaczyk, Eric D},
    booktitle = {The Astrophysical Journal},
    citeulike-article-id = {13901325},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.5161},
    keywords = {haar, poisson, regression, shrinkage, thresholding},
    pages = {340--349},
    posted-at = {2016-01-08 22:39:18},
    priority = {2},
    title = {{Non-Parametric Estimation of Gamma-Ray Burst Intensities Using Haar Wavelets.}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.5161},
    year = {1996}
}

@article{silverman1985some,
 ISSN = {00359246},
 URL = {http://www.jstor.org/stable/2345542},
 abstract = {Non-parametric regression using cubic splines is an attractive, flexible and widely-applicable approach to curve estimation. Although the basic idea was formulated many years ago, the method is not as widely known or adopted as perhaps it should be. The topics and examples discussed in this paper are intended to promote the understanding and extend the practicability of the spline smoothing methodology. Particular subjects covered include the basic principles of the method; the relation with moving average and other smoothing methods; the automatic choice of the amount of smoothing; and the use of residuals for diagnostic checking and model adaptation. The question of providing inference regions for curves-and for relevant properties of curves--is approached via a finite-dimensional Bayesian formulation.},
 author = {B. W. Silverman},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {1},
 pages = {1-52},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Some Aspects of the Spline Smoothing Approach to Non-Parametric Regression Curve Fitting},
 volume = {47},
 year = {1985}
}



@article{Beylkin1992Ontherepresentation,
 ISSN = {00361429},
 URL = {http://www.jstor.org/stable/2158264},
 abstract = {This paper describes exact and explicit representations of the differential operators, d<sup>n</sup>/dx<sup>n</sup>, n = 1, 2, ⋯, in orthonormal bases of compactly supported wavelets as well as the representations of the Hilbert transform and fractional derivatives. The method of computing these representations is directly applicable to multidimensional convolution operators. Also, sparse representations of shift operators in orthonormal bases of compactly supported wavelets are discussed and a fast algorithm requiring O(N log N) operations for computing the wavelet coefficients of all N circulant shifts of a vector of the length N = 2<sup>n</sup> is constructed. As an example of an application of this algorithm, it is shown that the storage requirements of the fast algorithm for applying the standard form of a pseudodifferential operator to a vector (see [G. Beylkin, R. R. Coifman, and V. Rokhlin, Comm. Pure. Appl. Math., 44 (1991), pp. 141-183]) may be reduced from O(N) to O(log<sup>2</sup> N) significant entries.},
 author = {G. Beylkin},
 journal = {SIAM Journal on Numerical Analysis},
 number = {6},
 pages = {1716-1740},
 publisher = {Society for Industrial and Applied Mathematics},
 title = {On the Representation of Operators in Bases of Compactly Supported Wavelets},
 volume = {29},
 year = {1992}
}


@Manual{Nason_wavethresh,
    title = {wavethresh: Wavelets statistics and transforms.},
    author = {Guy Nason},
    year = {2013},
    note = {R package version 4.6.6},
    url = {http://CRAN.R-project.org/package=wavethresh},
  }


@article{Zhang2008Modelbased,
    abstract = {{We present Model-based Analysis of ChIP-Seq data, MACS, which analyzes data generated by short read sequencers such as Solexa's Genome Analyzer. MACS empirically models the shift size of ChIP-Seq tags, and uses it to improve the spatial resolution of predicted binding sites. MACS also uses a dynamic Poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. MACS compares favorably to existing ChIP-Seq peak-finding algorithms, and is freely available.}},
    author = {Zhang, Yong and Liu, Tao and Meyer, Clifford A. and Eeckhoute, J\'{e}r\^{o}me and Johnson, David S. and Bernstein, Bradley E. and Nusbaum, Chad and Myers, Richard M. and Brown, Myles and Li, Wei and Liu, X. Shirley},
    citeulike-article-id = {3281478},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/gb-2008-9-9-r137},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2592715/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18798982},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18798982},
    day = {17},
    doi = {10.1186/gb-2008-9-9-r137},
    issn = {1474-760X},
    journal = {Genome biology},
    keywords = {peak, sequencing},
    month = sep,
    number = {9},
    pages = {R137+},
    pmcid = {PMC2592715},
    pmid = {18798982},
    posted-at = {2016-03-02 16:45:26},
    priority = {2},
    publisher = {BioMed Central Ltd},
    title = {{Model-based analysis of ChIP-Seq (MACS).}},
    url = {http://dx.doi.org/10.1186/gb-2008-9-9-r137},
    volume = {9},
    year = {2008}
}


@electronic{Cande00,
    abstract = {{It is widely believed that to efficiently represent an otherwise smooth object with discontinuities along edges, one must use an adaptive representation that in some sense `tracks' the shape of the discontinuity set. This folk-belief -- some would say folk-theorem -- is incorrect. At the very least, the possible quantitative advantage of such adaptation is vastly smaller than commonly believed. We have recently constructed a tight frame of curvelets which provides stable, efficient, and near-optimal representation of otherwise smooth objects having discontinuities along smooth curves. By applying naive thresholding to the curvelet transform of such an object, one can form m-term approximations with rate of L 2 approximation rivaling the rate obtainable by complex adaptive schemes which attempt to `track' the discontinuity set. In this article we explain the basic issues of efficient m-term approximation, the construction of efficient adaptive representation, the construction ...}},
    author = {Candes, Emmanuel J. and Emmanuel, J. C. and Donoho, David L.},
    citeulike-article-id = {4186092},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.34.2419},
    key = {Cande00},
    keywords = {curvelets, imaging, shrinkage, thresholding, wavelets},
    posted-at = {2016-03-03 20:42:46},
    priority = {2},
    title = {{Curvelets - A Surprisingly Effective Nonadaptive Representation For Objects with Edges}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.34.2419},
    year = {2000}
}

@book{Daubechies1992Ten,
    abstract = {{This book is both a tutorial on wavelets and a review of the most
advanced research in this domain. The topics covered include the
continuous wavelet transform of J. Morlet and A. Grossmann, several
important results on time-frequency localization (such as the
Balian-Low theorem and the Landau-Pollack-Slepian theory), a complete
study of the "frame" structure for a discrete set of wavelets, the
multiresolution analysis and orthonormal bases of Y. Meyer, and
finally the beautiful construction of compactly supported wavelets
from filter banks (which is due to the author).
<P>
As mentioned in the introduction, this is a mathematics book that
states and proves many theorems. In addition, it also gives many
practical examples and describes several applications (in particular,
in signal processing, image coding and numerical analysis).}},
    address = {Philadelphia, PA},
    author = {Daubechies, Ingrid},
    citeulike-article-id = {416053},
    citeulike-linkout-0 = {http://www.ams.org/mathscinet-getitem?mr=1162107},
    keywords = {math, signalprocessing, wavelets},
    mrnumber = {MR1162107},
    posted-at = {2005-11-30 18:13:58},
    priority = {2},
    publisher = {Society for Industrial and Applied Mathematics (SIAM)},
    series = {CBMS-NSF Regional Conference Series in Applied Mathematics},
    title = {{Ten lectures on wavelets}},
    url = {http://www.ams.org/mathscinet-getitem?mr=1162107},
    volume = {61},
    year = {1992}
}


@article{Wilbanks2010Evaluation,
    abstract = {{Next-generation DNA sequencing coupled with chromatin immunoprecipitation (ChIP-seq) is revolutionizing our ability to interrogate whole genome protein-DNA interactions. Identification of protein binding sites from ChIP-seq data has required novel computational tools, distinct from those used for the analysis of ChIP-Chip experiments. The growing popularity of ChIP-seq spurred the development of many different analytical programs (at last count, we noted 31 open source methods), each with some purported advantage. Given that the literature is dense and empirical benchmarking challenging, selecting an appropriate method for ChIP-seq analysis has become a daunting task. Herein we compare the performance of eleven different peak calling programs on common empirical, transcription factor datasets and measure their sensitivity, accuracy and usability. Our analysis provides an unbiased critical assessment of available technologies, and should assist researchers in choosing a suitable tool for handling ChIP-seq data.}},
    author = {Wilbanks, Elizabeth G. and Facciotti, Marc T.},
    citeulike-article-id = {7465559},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0011471},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2900203/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/20628599},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=20628599},
    day = {8},
    doi = {10.1371/journal.pone.0011471},
    issn = {1932-6203},
    journal = {PLoS ONE},
    keywords = {chip-seq, peak-calling, poisson},
    month = jul,
    number = {7},
    pages = {e11471+},
    pmcid = {PMC2900203},
    pmid = {20628599},
    posted-at = {2016-03-03 21:10:52},
    priority = {2},
    publisher = {Public Library of Science},
    title = {{Evaluation of Algorithm Performance in ChIP-Seq Peak Detection}},
    url = {http://dx.doi.org/10.1371/journal.pone.0011471},
    volume = {5},
    year = {2010}
}


